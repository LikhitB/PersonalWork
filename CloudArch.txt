IAM
 
iam Policies consists of 
  1.Version
  2.Id
  3.Statement
     i.Sid
     ii.Effect  -> Allow/Deny
     iii.Principal -> account/user/role to which this policy is applied to
     iv.Actions -> list of actions this policy allow/deny
     v.Resource  -> list of rss to which need to be applied
iam-password policy  
     i.allow all users to change their own passwords
     ii.require users to change their password after some time.
     iii.prevent password reuse
ways to access AWS 
      i.AWS management console -> protected by MFA
      ii. AWS CLI -> protected by access keys
      iii.AWS SDK  -> """""""
access key has 2 parts  1. access key ID  2.secret access key
aws cloudshell is a inbuilt terminal act as CLI in aws.
aws policy is attached to aws roles which are assigned to a service
 
iam security tools
  i.IAM creditial report(accout level)  -> lists all the users and the status of the various credentials
  ii.IAM Access Advisor(user level) -> shows the service permissions granted to a user and services which are last accessed
 
 
EC2
 
sizing and configuration options
     i.two types of storage space 
        1.EBS & EFS -> network
        2.EC2 instance store -> ec2 instance store
     ii.firewall rules can be set to security group
     iii.bootstrap script -> ec2 user data which descibes create/update on the first launch of the ec2 instance
 
types of ec2 instances
     i.for example m5.2large -> m(instance class) ,5(genereation), 2xlarge(size within the instance class)
    ii.General purpose  -> great for diversity of workloads such as web servers or code repos  eg.t2.micro
    iii.Compute optimized -> Mainly for compute-intensive tasks that require high performance
        1.batch processing 
        2.dedicated gaming servers
        3.ML
     iv.Memory optimized 
         1.used for fast performance workloads that process large datasets in memory
         2.high performance relational/non relational DB
         3.distributed web scale cache stores
         4.applications performing real-time processing of big unstructured data
     v.storage optimized  -> used for storage-intensive taskas that reuire high sequential r/w access to large datasets
         1.high frequency online transaction processing(OLTP)
         2.relational and NoSql DB
         3.cache for in-memory database
         4.data warehousing application/distibuted file systems
security groups
   i.these are firewalls on ec2 instances
   ii.they regulate 
       1.access to ports
       2.autorised IP rages 
       3.control inbound(blocked by default) and outbound(authorised by default) network.
       4.we can set only allow rules
       5.can be attached to multiple instances
 
placement groups
    i.cluster-> generally used for low latency and fast inter-instnce communication.
    ii. spread -> can span across AZ , limited to 7 instances per AZ per placement group
    iii.partiton -> 7 partitons per AZ and each partitons can have many instances
 
elastic network interface(ENI)
    i.its a network component of VPC that represents a virtual network card.
    ii.it consists of 
         1.Primary private IPv4 address
         2.One or more secondary private IPv4 addresses
         3.One Elastic IP address (IPv4) per private IPv4 address
         4.One or more security groups
         5.A MAC address
         6.A source/destination check flag
    iii.types of ENI -> primary and secondary
 
 
EBS Volumes
    i.these are bound to a specific AZ 
    ii.mounted to one instance at a time where one instance can have multiple EBS volumes.
    iii.to move to diff AZ first we need a snapshots
    iv.deleteOnTermination attribute is enabled by default
    v.snapshots -> its a type of backup used for transfer of EBS volumes between AZ.
    vi.EBS snapshote archives ->move snapshots to archive tier that is 75% cheaper which takes 24 to 72 hrs for restoring the archive.
    vii.forsce snapshot restore(FSR) -> used for forcefull init of snapshots , generaly costly.
 
AMI
   i.these are built in specific region
   ii.we can launch EC2 instance from 
      1.public AMI -> aws provided
      2.own AMI 
      3.AWS marketplace -> buy/sell ,AMI
   iii.building an AMI will also create EBS snapshots.
 
EC2 instace store
   i.its a high performance hardware disk
   ii.better I/O performance
   iii.lose their dtorage if they ec2 instance are stopped
 
Types of EBS volumes
    i.these are chracterized in size/throughput/iops(I/O operations per second)
    ii.gp/io type volumes are boot volumes(directly attached to the EC2 instances and have underlying OS within them)
    iii.6 types of volumes are
       1.gp2/gp3(SSD) -> default choice for most workloads,general purpose(small DB),balanced performance and cost,size(1 GB to 16 TB),can increase IOPS                      
         upto 16K.
         i.gp2-> 3IOPS/GB(baseline),250mbps throughput,depends on the size
         ii.gp3 -> 3000IOPS(baseline),1tbps throughput and cheaper than gp2,size independent.
 
       2.io1/io2 block express(SSD) -> mission critical , large DB,low latency workloads,I/O instensive,size(4-16TB),these are multi-attach type of volumes(only can be attached to the 16 EC2 instances at a time)
          i.io1 -> 64k IOPS,independent of storage for increase the PIOPS(provisioned IOPS)
          ii.io2 -> 256k IOPS, depends on the IOPS:GB i.e 1000:1
 
       3.st 1(throughput optimized HDD) -> big data,data warehousing,high throughput,low IOPS,streaming throughput,large sequential workloads,
       4.sc 1(cold HDD)-> infrequent accessed data(backups,archives),lowest cost,lowest throughput,cheap storage,rarely accessed data.
EBS encryption
    i.when we encrypt an EBS volume we get
      1.data at rest is encrypted inside the volume
      2.all the data in flight moving bw instances are encrypted
      3.all snapshots are encrypted
      4.volumes created are encrypted
      5.we can create an encrypted snapshot from an unencrypted snaphot by copying it so that we could create an encrypted volume out of it.
EFS
i.it works with ec2 in multi AZ
ii.uses NHS protocol
iii.uses security group to control access to EFS
iv.compatible with linux based AMI
v.performance classes of EFS
  1.EFS scale
  2.performance mode
    i.general purpose,max I/O
  3.throughput mode 
    i.bursting,provisioned,elastic
vi.storage classes
   1.standard-> for freq accessed files
   2.infrequent access(EFS-IA) -> cost for retrieve files,lower price to store
   3.archive -> rarely accessed data, 50% cheaper
   4 lifecycle policies to move the files bw storage classes
 
EBS vs EFS 
1.EBS
  i.attached to one instance only excpet multi-attach io1/io2
  ii.locked at AZ
  iii.migration of ebs volume can be done by the use of snapshots
  iv.root EBS vols are terminated of the EC2 instace gets terminated.
2.EFS
  i.mount to 100s of instances across AZ
  ii.only for linux based instances
  iii.share website files


section-8 to section-9(pending)

AWS S3
1.Object values are the content of the body 
  i.max object size is 5TB
  ii.S3 buckets are regional level
  iii.object have a key its a full path of the file
2.Security
  i.IAM Policies
  ii.Resourse-Based
     i.bucket policies
     ii.Object Access Control list
     iii.Bucket Access Control list
  iii.IAM principla can access an S3 object if the user IAM permissions allow it or the rss policy allows it and there's no explcit deny.
  iv.encrypt object using S3.
3.S3 Bucket Policies
   i.Resources -> bucket and objects
   ii.Effect -> Allow/Deny
   iii.Actions -> Set of API to allow or deny
   iv.Pricipal-> account or user the policy must apply to
   we can also set the cross account access using bucket policies
4.Amazon S3- Replication
  i.must enable the versioning in source and destination buckets
  ii.CRR(cross region) and SRR(same region) 
5.S3 storage classes
  i.S3 Standard 
    1.used for frq accessed data
    2.low latency and high throughput
    3.use dfor big data analytics and mobile and gamin apps
  ii.S3 infreq access
    1.For data which is less freq accessed and req rapid access when needed 
      i.s3 standard infreq access-> used for disaster recovery backups
      ii.s3 one zone infreq access -> high durable than standard infreq access  and used for storing secondary backup copies of on-premise data
  iii.S3 Glacier storage classes
     1.Manly used for archiving/backup 
       i.cost-> storage+ object retrieval cost
     2.Glacier instant retrieval->ms retrieval and great for accessed once a quarter and min storage duration is 90 days.
     3.Glacier flexible retrieval -> expedited(1 to 5mins),standard(3 to 5 hrs),bulk(5 to 12 hrs)-free and min storage duration is 90 days
     4.Glacier deep archive-> for long term storage standard(12 hrs),bulk(48 hrs),min storage of 180 days. 
  iv.S3 intelligent teiring
     1.moves the data between various teirs and there is no retrieval charges.
  v.S3 Baseline Performance
     1.applications can achiee at least 3500 put/copy/post/delete and 5500 get/head
     2.It can be optimised by 
       i.multi-part upload
         1.recomeneded for files >100MB
         2.parllel uploads
       ii.S3 transfer acceleration acceleration
         1.increase the tranfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket
       iii.S3 Byte-Range fetches
           1.parallelize GETs 
  vi.S3 Batch Operations
     1.performing bulk operations on the existing s3 objects with a single request example,
       i.modify object metadata and properties
       ii.encrypt unencrypted objects
       iii.modify ACL's tags
     2.these manages the retries,tracks progress,sends completion notifications.
  vii.S3 storage lens
      1.it provides default dashboard
      2.it consists of metrics -> 1.summary metrics
                                  2.cost optimization metrics
                                  3.Data protection metrics
                                  4.Access management metrics
                                  5.event metrics
                                  6.performance metrics
                                  7.Activity metrics
                                  8.detailed status code metrics.

6.Amazon S3 Encryption
    1.we can encrypt in s3 bucket using 4 methods
      1.server-side encryption(sse)
       i.using KMS method(SSE-S3)
         i.using keys handled,managed,and owned by AWS.
         ii.objects are encrypted on server side.
       ii.with KMS keys stored AWS KMS(SSE-KMS)
         i.keys are managed by AWS KMS and this has more user 
           control+audit key usage using cloud trial.
         ii.server side encrypted objects.
       iii.sse with customer provided keys(SSE-C)
         i.server-side encryption using keys fully managed by the customer
         ii.s3 does not store the encryption key u provide.
         iii.https must be used
      2.client side encryption
        i.uses client libraries such as amazon s3 client-side encryption library.
        ii.client must encrypt data themselves before sending to AWS S3.
        iii.cusotmer fully manages keys and encryption cycle.
      3.Encryption in transit(SSL/TLS)
        i.https/https
        ii.we can force encryption in transit through the use of bucket policy.
      4.Default encryption vs bucket policy
      5.CORS -> screenshot(ss)
      6.S3 Access logs
        i.used ot log all access to s3 buckets
        ii.the target access log bucket ust be in the same AWS region.
      7.S3 Pre-signed URLS
        i.we can generate URLSs using s3 console,AWS CLI or SDK
        ii.use cases such as allow only logged-in users to download a premium video from s3 bucket.
       8.S3 Glacier Vault Lock
         i.Adopt a worm(write one read many model)
         ii.create a vault lock policy
         iii.An object can never be deleted after its out into the vault lock.
       9.S3 Object Lock(versioning and object lock must be enabled)
         i.Amazon S3 Object Lock is a feature that prevents objects from being deleted or overwritten for a fixed amount of time or indefinitely.
           It helps you meet regulatory compliance (like financial or healthcare rules) by ensuring data immutability â€” i.e., once written, it cannot be         
           changed or deleted.
         ii.adopt a WORM(write once read many) model
         iii.block an object version deletion for a specified amount of time.
         iv.It has two types of retention modes
             1.Compliance-version of the object cant be overwritten or deleted by any user including the root user even period of the retention cant be                          changed or shorten
             2.governance-most users cant overwrite or delete an object version and some user have special permissions to change the retention of the         object.
         v.retention period is a fixed period and it can be extended
         vi.legal hold give the option of preventing the deletion but only manual removal
       10.S3 Access Points-> screenshot
       11.Access Points - VPC Origin
          i.we can define the access pointe to be accessible within the vpc
          ii.inorder to access an endpoint we need to create a VPC endpoint.
          iii.ther will be a VPC endpoint policy therefore it must allow access to target bucket and access point.
       12.S3 Object lambda 
          i.before the communication from the caller AWS lambda functions changes its retrieved object.
          ii.so the lambda function is created connected by S3 access point and the S3 object lambda access point.
          iii.see the screenshot. 

  
    
        
         
   
  
  
